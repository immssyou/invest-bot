# main.py

import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import JSONLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from langgraph.graph import MessagesState
from langchain_core.messages import HumanMessage
from langfuse import Langfuse
from langfuse.langchain import CallbackHandler
from langchain_tavily import TavilySearch
search_web = TavilySearch(max_results=2)

load_dotenv()

vectordb = None
langfuse = None
callback_handler = None

# Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
if os.getenv("LANGFUSE_PUBLIC_KEY") and os.getenv("LANGFUSE_SECRET_KEY"):
    langfuse = Langfuse(
        public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
        secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
        host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com")
    )
    callback_handler = CallbackHandler()

### ë°ì´í„° ë¡œë”© ë° ë²¡í„° DB êµ¬ì¶•
def load_json_docs(json_path: str):
    loader = JSONLoader(
        file_path=json_path,
        jq_schema=".[] | {page_content: .content, metadata: {id: .id, title: .title}}",
        text_content=False
    )
    docs = loader.load()
    for doc in docs:
        if isinstance(doc.page_content, str):
            try:
                doc.page_content = doc.page_content.encode('utf-8').decode('unicode_escape')
            except Exception:
                pass
    return docs

def split_docs(docs):
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    return splitter.split_documents(docs)

def build_vectorstore(chunks):
    embeddings = OpenAIEmbeddings()
    vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory="./chroma_db")
    return vectordb

### ë„êµ¬ ì •ì˜
@tool
def search_meeting_data(query: str) -> str:
    """
    ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì íšŒì˜ë¡ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    global vectordb
    if vectordb is None:
        return "ë²¡í„°DBê°€ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    docs = vectordb.similarity_search(query, k=3)
    if len(docs) > 0:
        return "\n\n".join([doc.page_content for doc in docs])
    return "ê´€ë ¨ íšŒì˜ë¡ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

tools = [search_meeting_data, search_web]
llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.7)

# LangGraph ReAct agent ìƒì„±
react_agent = create_react_agent(
    model=llm,
    tools=tools,
    # system promptëŠ” MessagesStateì—ì„œ ì²« ë©”ì‹œì§€ë¡œ ì „ë‹¬
)

def main():
    global vectordb
    st.set_page_config(page_title="ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì Q&A", layout="wide")
    st.title("ğŸš€ ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì íšŒì˜ë¡ Q&A (RAG + LangGraph ReAct Agent + Langfuse)")

    # Langfuse ìƒíƒœ í‘œì‹œ
    if langfuse:
        st.success("âœ… Langfuse ëª¨ë‹ˆí„°ë§ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤")
    else:
        st.warning("âš ï¸ Langfuse í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë‹ˆí„°ë§ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

    with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
        docs = load_json_docs("./data/startup_investment_meeting_data_30.json")
        chunks = split_docs(docs)
        vectordb = build_vectorstore(chunks)

    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", "ì´ë²ˆ ë¼ìš´ë“œ íˆ¬ìì—ì„œ ê°€ì¥ ì¤‘ì ì„ ë‘” ë¶€ë¶„ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”")
    if st.button("ì§ˆë¬¸í•˜ê¸°") and user_input:
        # Langfuse ì½œë°± í•¸ë“¤ëŸ¬ê°€ ìˆìœ¼ë©´ ì „ë‹¬ (LangGraphëŠ” configë¡œ ì½œë°± ì§€ì› X, ì¶”í›„ í™•ì¥)
        system_message = "You are a helpful AI assistant. íšŒì˜ë¡ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”. ë‹µë³€ì— ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”."
        messages = [
            HumanMessage(content=system_message),
            HumanMessage(content=user_input)
        ]
        result = react_agent.invoke({"messages": messages}, config={"callbacks": [callback_handler] if callback_handler else {}})
        st.markdown("---")
        st.subheader("ğŸ§  ë‹µë³€")
        st.write(result['messages'][-1].content)

if __name__ == "__main__":
    main()